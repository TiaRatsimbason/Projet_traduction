{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a996d864-6a89-4513-95ba-2edb457d25be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Utilisation simple des identifieurs de langues** (rev1) **avec les :**\n",
    ">## **- Tokenisations BERT ou Tiktoken**\n",
    ">## **- Classificateurs Naïve Bayes et Gradiant Boosting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e67500-a4c1-4d58-8f4a-1be20434be6d",
   "metadata": {},
   "source": [
    "#### **Choix du tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb14523-04a8-424c-976a-d61585c0bbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Choix de la Tokenisation (False = BERT, True Tiktoken)\n",
    "titoken_tokenization = True\n",
    "\n",
    "## Pour résoudre les problème de mémoire et de performances\n",
    "nb_phrase_lang = 1000000\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bad4ba-8678-41a4-9008-ab1915eddae6",
   "metadata": {},
   "source": [
    "#### **Lectures des phrases de \"sentences.csv\", et de leur étiquette \"Langue\" pour les langues sélectionnées**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "491d66b2-90bd-49e9-99cb-9601edf52a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes de sentence.csv: 1750000\n",
      "Nombre de phrases par langue  ['eng', 'fra', 'deu', 'spa', 'ita'] : [350000, 350000, 350000, 350000, 350000]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lan_code</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng</td>\n",
       "      <td>She is afraid of death.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ita</td>\n",
       "      <td>Indovina cosa scelgo io.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spa</td>\n",
       "      <td>¿Puedo ayudarlo? \"No, gracias. Solo estoy mira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ita</td>\n",
       "      <td>Io non sono una fricchettona!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deu</td>\n",
       "      <td>Es sind schon fast 10 Jahre vergangen, aber du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spa</td>\n",
       "      <td>Creía que me quería.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eng</td>\n",
       "      <td>This school sets high moral standards for pupils.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eng</td>\n",
       "      <td>Man is judged by his courage, woman by her charm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fra</td>\n",
       "      <td>Je mange des pruneaux sucrés.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fra</td>\n",
       "      <td>J'ai écrit une chanson pour toi.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lan_code                                           sentence\n",
       "0      eng                            She is afraid of death.\n",
       "1      ita                           Indovina cosa scelgo io.\n",
       "2      spa  ¿Puedo ayudarlo? \"No, gracias. Solo estoy mira...\n",
       "3      ita                      Io non sono una fricchettona!\n",
       "4      deu  Es sind schon fast 10 Jahre vergangen, aber du...\n",
       "5      spa                               Creía que me quería.\n",
       "6      eng  This school sets high moral standards for pupils.\n",
       "7      eng  Man is judged by his courage, woman by her charm.\n",
       "8      fra                      Je mange des pruneaux sucrés.\n",
       "9      fra                   J'ai écrit une chanson pour toi."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lan_code</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1749990</th>\n",
       "      <td>deu</td>\n",
       "      <td>Es geschieht heutzutage ja so viel in unserer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749991</th>\n",
       "      <td>spa</td>\n",
       "      <td>El almuerzo está preparado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749992</th>\n",
       "      <td>eng</td>\n",
       "      <td>I've seen enough.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749993</th>\n",
       "      <td>ita</td>\n",
       "      <td>Hanno accelerato il passo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749994</th>\n",
       "      <td>fra</td>\n",
       "      <td>Elle en pince pour ce garçon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749995</th>\n",
       "      <td>deu</td>\n",
       "      <td>Wer von uns wünschte nicht manchmal, dass er d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749996</th>\n",
       "      <td>ita</td>\n",
       "      <td>No! Io odio i broccoli!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749997</th>\n",
       "      <td>fra</td>\n",
       "      <td>Tu seras tuée !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749998</th>\n",
       "      <td>fra</td>\n",
       "      <td>Tom aurait dû manger plus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749999</th>\n",
       "      <td>eng</td>\n",
       "      <td>He took the video to a local TV station.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lan_code                                           sentence\n",
       "1749990      deu  Es geschieht heutzutage ja so viel in unserer ...\n",
       "1749991      spa                        El almuerzo está preparado.\n",
       "1749992      eng                                  I've seen enough.\n",
       "1749993      ita                         Hanno accelerato il passo.\n",
       "1749994      fra                      Elle en pince pour ce garçon.\n",
       "1749995      deu  Wer von uns wünschte nicht manchmal, dass er d...\n",
       "1749996      ita                            No! Io odio i broccoli!\n",
       "1749997      fra                                    Tu seras tuée !\n",
       "1749998      fra                         Tom aurait dû manger plus.\n",
       "1749999      eng           He took the video to a local TV station."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ouvrir le fichier d'entrée en mode lecture\n",
    "def create_lang_df(path):\n",
    "    df = pd.read_csv(path, index_col ='id')\n",
    "    return df\n",
    "\n",
    "df_big = create_lang_df('../data/multilingue/sentences.csv')\n",
    "lan_code = ['eng','fra','deu','spa','ita']\n",
    "df = pd.DataFrame(columns=df_big.columns)\n",
    "for i in range(len(lan_code)):\n",
    "    df= pd.concat([df, df_big[df_big['lan_code']==lan_code[i]].iloc[:nb_phrase_lang]])\n",
    "df = df.sample(frac=1, random_state=3).reset_index(drop=True)\n",
    "n_rows = len(df)\n",
    "print('Nombre de lignes de sentence.csv:',n_rows)\n",
    "nb_phrases_lang =[]\n",
    "for l in lan_code:\n",
    "    nb_phrases_lang.append(sum(df['lan_code']==l))\n",
    "print(\"Nombre de phrases par langue \",lan_code,\":\",nb_phrases_lang)\n",
    "display(df.head(10))\n",
    "display(df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78bb348-f3c0-4455-b39e-a0b26527556a",
   "metadata": {},
   "source": [
    "#### **Selection du tokenizer** en fonction de la variable titoken_tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce260244-a177-43b5-accf-0564548c2fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selection du tokenizer\n",
    "if titoken_tokenization:\n",
    "    import tiktoken\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "else:\n",
    "    from transformers import BertTokenizerFast\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb9b00-6cc3-47bc-afcf-b00fdef8738b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Chargement des Tokens utilisés**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df235a48-3ea5-47a7-af0a-f91fd20af84e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "def load_dict_token():\n",
    "    if titoken_tokenization: path = '../data/dict_token_tiktoken'\n",
    "    else: path = '../data/dict_token_BERT'\n",
    "    \n",
    "    with open(path, 'rb') as fichier:\n",
    "        dict_ids = pickle.load(fichier)\n",
    "        # Définition d'une liste 'écrite' des tokens\n",
    "        decoded_keys = [tokenizer.decode([key]) for key in list(dict_ids.keys())]\n",
    "    return dict_ids, decoded_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a96239-98ab-47b0-acf9-1660e16fc9ab",
   "metadata": {},
   "source": [
    "#### **Choix du nom du fichier de sauvegarde du classifieur**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acc778b1-231d-42c6-9218-144ee7e88da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_file_name(titoken_tokenization, classifier):\n",
    "    if titoken_tokenization:\n",
    "        return \"id_lang_tiktoken_\"+classifier+\".pkl\"\n",
    "    else:\n",
    "        return \"id_lang_BERT_\"+classifier+\".pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923233dd-f03a-400a-bc7c-b5fc4914ca8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Création d'un classificateur avec l'algorithme Naïve Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b3449f-f635-402a-b3bf-5c163fadad52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "# Chargement du classificateur sauvé\n",
    "clf_nb = joblib.load(\"../data/\"+get_file_name(titoken_tokenization,\"nb\"))\n",
    "dict_ids, decoded_keys = load_dict_token()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95249cde-cfc5-487c-b579-c590ee84ca42",
   "metadata": {},
   "source": [
    "#### **Création d'un classificateur avec l'algorithme Gradiant Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbfa6b8c-172e-4cb7-ab10-20ed7154c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Chargement du classificateur sauvé\n",
    "clf_gb = joblib.load(\"../data/\"+get_file_name(titoken_tokenization,\"gb\"))\n",
    "######### dict_ids, decoded_keys = load_dict_token() ######### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de709b0-83c2-4b3f-a018-ea6c10531f99",
   "metadata": {},
   "source": [
    "#### **Definition de fonctions identificateur de langue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d8d36f-3f1c-49a8-8367-38158996865c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Créez un DataFrame BOW avec les phrases (lignes) et les fréquences de chaque token (colonnes)\n",
    "def create_BOW(data):\n",
    "    BOW = []\n",
    "    try:\n",
    "        if 'str' in str(type(data)):\n",
    "            l_tokenised = tokenizer.encode(data)\n",
    "            BOW.append([l_tokenised.count(token) for token in dict_ids])\n",
    "        else:\n",
    "            for ligne in data:\n",
    "                l_tokenised = tokenizer.encode(ligne)\n",
    "                BOW.append([l_tokenised.count(token) for token in dict_ids])\n",
    "    except:\n",
    "        BOW.append([tokenizer.encode(\" \").count(token) for token in dict_ids])\n",
    "    return BOW\n",
    "\n",
    "def lang_id_nb(sentences):\n",
    "    return clf_nb.predict(create_BOW(sentences))\n",
    "\n",
    "def lang_id_gb(sentences):\n",
    "    return clf_gb.predict(create_BOW(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82b0a7-3649-4c66-97d2-e38c52e2fbfc",
   "metadata": {},
   "source": [
    "#### **Exemples d'utilisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a73abd8-94fb-4ed5-8ad9-3308c95ca077",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\t lang\t Phrase\n",
      "0 -\t eng \t france is often snowy during spring , and it is relaxing in january .\n",
      "1 -\t fra \t elle adore les voitures très luxueuses, et toi ?\n",
      "2 -\t eng \t she loves very luxurious cars, don't you?\n",
      "3 -\t spa \t vamos a la playa\n",
      "4 -\t deu \t Ich heiße Keyne, und das ist wunderbar\n",
      "5 -\t e,f,d \t she loves you, mais elle te hait aussi, and das ist traurig\n",
      "6 -\t en \t I ate caviar\n",
      "7 -\t ita \t Vogliamo visitare il Colosseo e nuotare nel Tevere.\n",
      "8 -\t ita \t Tom è impegnato adesso, per cui non può parlare con te.\n",
      "9 -\t ita \t Faccio colazione alle sette ogni mattina.\n",
      "10 -\t ita \t Fuori ci sono i bambini che giocano e mettono allegria.\n",
      "11 -\t fra \t L'année dernière je suis allé en Belgique et en Israël.\n",
      "12 -\t fra \t Peu reste à faire.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Instanciation d'exemples\n",
    "\n",
    "sentence_no = random.sample(range(len(df)),5)\n",
    "\n",
    "exemples = [\"france is often snowy during spring , and it is relaxing in january .\",\n",
    "           \"elle adore les voitures très luxueuses, et toi ?\",\n",
    "           \"she loves very luxurious cars, don't you?\",\n",
    "           \"vamos a la playa\",\n",
    "           \"Ich heiße Keyne, und das ist wunderbar\",\n",
    "           \"she loves you, mais elle te hait aussi, and das ist traurig\", # Attention à cette phrase trilingue\n",
    "           \"I ate caviar\", \n",
    "           \"Vogliamo visitare il Colosseo e nuotare nel Tevere.\",\n",
    "            df['sentence'].iloc[sentence_no[0]],\n",
    "            df['sentence'].iloc[sentence_no[1]],\n",
    "            df['sentence'].iloc[sentence_no[2]],\n",
    "            df['sentence'].iloc[sentence_no[3]],\n",
    "            df['sentence'].iloc[sentence_no[4]],\n",
    "          ]\n",
    "lang_exemples = ['eng','fra','eng','spa','deu','e,f,d','en','ita',df['lan_code'].iloc[sentence_no[0]],df['lan_code'].iloc[sentence_no[1]],df['lan_code'].iloc[sentence_no[2]],\n",
    "                 df['lan_code'].iloc[sentence_no[3]],df['lan_code'].iloc[sentence_no[4]]]\n",
    "print('no\\t lang\\t Phrase')                            \n",
    "for i in range(len(exemples)):\n",
    "    print(i,'-\\t',lang_exemples[i],'\\t',exemples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b4a279-9aea-494e-b468-de0f024cd899",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langue réelle\tPréd. Naive B.\tPréd. Grad. B.\tPhrase\n",
      "eng\t\teng\t\teng\t\tfrance is often snowy during spring , and it is relaxing in january .\n",
      "fra\t\tfra\t\tfra\t\telle adore les voitures très luxueuses, et toi ?\n",
      "eng\t\teng\t\teng\t\tshe loves very luxurious cars, don't you?\n",
      "spa\t\tspa\t\tspa\t\tvamos a la playa\n",
      "deu\t\tdeu\t\tdeu\t\tIch heiße Keyne, und das ist wunderbar\n",
      "e,f,d\t\tfra\t\tdeu\t\tshe loves you, mais elle te hait aussi, and das ist traurig\n",
      "en\t\tita\t\teng\t\tI ate caviar\n",
      "ita\t\tita\t\tita\t\tVogliamo visitare il Colosseo e nuotare nel Tevere.\n",
      "ita\t\tita\t\tita\t\tTom è impegnato adesso, per cui non può parlare con te.\n",
      "ita\t\tita\t\tita\t\tFaccio colazione alle sette ogni mattina.\n",
      "ita\t\tita\t\tita\t\tFuori ci sono i bambini che giocano e mettono allegria.\n",
      "fra\t\tfra\t\tfra\t\tL'année dernière je suis allé en Belgique et en Israël.\n",
      "fra\t\tfra\t\tfra\t\tPeu reste à faire.\n"
     ]
    }
   ],
   "source": [
    "# Affichage des prédictions\n",
    "print(\"Langue réelle\\tPréd. Naive B.\\tPréd. Grad. B.\\tPhrase\")\n",
    "for i in range(len(exemples)):\n",
    "    print(lang_exemples[i]+'\\t\\t'+lang_id_nb(exemples[i])[0]+'\\t\\t'+lang_id_gb(exemples[i])[0]+'\\t\\t'+exemples[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed8d1c1-e5dd-4a17-8aee-1305fbf4c45a",
   "metadata": {},
   "source": [
    "> **Recherche des phrases mal classées par Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d458174a-c2e1-41e8-a84a-35584eaac751",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - No 116  - Réel: eng  Prédit: spa      A guilty conscience needs no accuser.  (proba=0.70)\n",
      "2 - No 185  - Réel: ita  Prédit: spa      Me lo traduci?  (proba=0.97)\n",
      "3 - No 209  - Réel: spa  Prédit: ita      Admiro tu talento.  (proba=0.60)\n",
      "4 - No 725  - Réel: fra  Prédit: spa      Tom a changé de boulot.  (proba=0.59)\n",
      "5 - No 731  - Réel: fra  Prédit: spa      Mary a aidé Tom.  (proba=0.89)\n",
      "6 - No 921  - Réel: ita  Prédit: fra      Ce la caveremo.  (proba=0.97)\n",
      "7 - No 1155  - Réel: spa  Prédit: ita      Usted miente cual periódico.  (proba=0.55)\n",
      "8 - No 1210  - Réel: ita  Prédit: spa      Tutto sarà nuovo?  (proba=0.58)\n",
      "9 - No 1254  - Réel: spa  Prédit: ita      La sala necesita una cortina nueva.  (proba=0.61)\n",
      "10 - No 1297  - Réel: eng  Prédit: spa      No dirty jokes!  (proba=0.67)\n",
      "11 - No 1325  - Réel: deu  Prédit: spa      Tom beleidigte Mary.  (proba=0.34)\n",
      "12 - No 1743  - Réel: ita  Prédit: spa      Marie era esigente.  (proba=0.88)\n",
      "13 - No 1841  - Réel: ita  Prédit: spa      Lo odio, lo odio, lo odio.  (proba=0.97)\n",
      "14 - No 1870  - Réel: spa  Prédit: ita      Tom ha estado evitando a Mary.  (proba=0.63)\n",
      "15 - No 1887  - Réel: spa  Prédit: ita      Ha empeorado la situación.  (proba=0.80)\n",
      "16 - No 1970  - Réel: spa  Prédit: ita      Tom odia a Mary.  (proba=0.45)\n",
      "17 - No 2101  - Réel: eng  Prédit: spa      Magda marries a Spaniard.  (proba=0.71)\n",
      "18 - No 2208  - Réel: eng  Prédit: ita      Spread Esperanto!  (proba=0.60)\n",
      "19 - No 2365  - Réel: spa  Prédit: ita      Aflójate la corbata.  (proba=0.91)\n",
      "20 - No 2491  - Réel: spa  Prédit: fra      El camino desciende.  (proba=0.55)\n",
      "21 - No 2659  - Réel: eng  Prédit: fra      Tom is an unrepentant sinner.  (proba=0.67)\n",
      "22 - No 2665  - Réel: eng  Prédit: spa      Penny wise, pound foolish.  (proba=0.57)\n",
      "23 - No 2689  - Réel: spa  Prédit: ita      Tom detesta a Mary.  (proba=0.57)\n",
      "24 - No 2973  - Réel: spa  Prédit: ita      Le da miedo bailar.  (proba=0.71)\n",
      "25 - No 3023  - Réel: ita  Prédit: fra      Tom ce l'ha fatta.  (proba=0.58)\n",
      "26 - No 3077  - Réel: deu  Prédit: ita      Arbeit adelt.  (proba=0.55)\n",
      "27 - No 3084  - Réel: ita  Prédit: eng      Smamma.  (proba=0.28)\n",
      "28 - No 3111  - Réel: fra  Prédit: spa      Tom a visité Londres.  (proba=0.90)\n",
      "29 - No 3195  - Réel: eng  Prédit: ita      Drunkards drink non stop.  (proba=0.96)\n",
      "30 - No 3577  - Réel: ita  Prédit: spa      Vengo.  (proba=0.78)\n"
     ]
    }
   ],
   "source": [
    "n_bad_max = 30\n",
    "n_bad = 0\n",
    "for i in range(len(df)):\n",
    "    if (n_bad<n_bad_max):\n",
    "        if (df['lan_code'].iloc[i] != lang_id_nb(df['sentence'].iloc[i])):\n",
    "            n_bad +=1\n",
    "            print(n_bad,'- No',i,' - Réel:',df['lan_code'].iloc[i],' Prédit:',lang_id_nb(df['sentence'].iloc[i])[0],'    ',\n",
    "                  df['sentence'].iloc[i],\" (proba={:.2f}\".format(max(clf_nb.predict_proba(np.array(create_BOW([df['sentence'].iloc[i]])))[0]))+\")\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
